{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools \n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "#importing key modeul to access api key\n",
    "import key\n",
    "OPENAI_KEY=key.OPENAI_KEY\n",
    "serpapi_key=key.serpapi_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "client=OpenAI(openai_api_key=OPENAI_KEY)\n",
    "tool=load_tools([\"serpapi\"],serpapi_api_key=serpapi_key,llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#creating an agent type\n",
    "agent=initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"can you tell me who won the recent world cup.?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"can you tell me the current 5 current afairs.?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#understanding how to call wikipeida api\n",
    "tool=load_tools([\"wikipedia\"],llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an agent type\n",
    "agent=initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"can you tell me more about recent cricket worldcup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"can you tell me what is current GSP of usa.?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CHAINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI(client=<openai.resources.completions.Completions object at 0x000001D9A7E54890>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001D9A82158D0>, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt=PromptTemplate.from_template(\"what is a good name for compnay that makes {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt=prompt.format(product=\"wine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmchain=LLMChain(llm=client,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "out=llmchain.run(\"Wine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Vineyard Vines\" '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# another example of chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"i want to open a resturant for {cuisine} food, suggest a fancy name for this\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['cuisine'], template='i want to open a resturant for {cuisine} food, suggest a fancy name for this')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmchain=LLMChain(llm=client,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmchain.run(\"indian\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmchain=LLMChain(llm=client,prompt=prompt_template,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mi want to open a resturant for american food, suggest a fancy name for this\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Stateside Dining Co.\" '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llmchain.run(\"american\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we want to combine multiple chain and set a sequence for that we use simple sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=[\"startup_name\"],\n",
    "    template=\"i want to start a startup for {startup_name}, suggest me a good name for this\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_chain=LLMChain(llm=client,prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_item=PromptTemplate(\n",
    "    input_variables=[\"name\"],\n",
    "    template=\"suggest some statergies for {name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "statergy_chain=LLMChain(llm=client,prompt=prompt_template_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we combine above two chain using the simple sequetial chain\n",
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleChain=SimpleSequentialChain(chains=[name_chain,statergy_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. \"IntelliGenius\":\n",
      "a. Develop a strong branding strategy that highlights the intelligence and expertise of the company.\n",
      "b. Partner with educational institutions to showcase the intelligence and potential of the company's technology.\n",
      "c. Offer free trials or demos to potential clients to showcase the power and capabilities of the technology.\n",
      "d. Invest in research and development to continuously improve and innovate the technology.\n",
      "e. Utilize social media and targeted marketing to reach out to potential clients in the tech and business sectors.\n",
      "f. Collaborate with other AI companies to expand knowledge and resources.\n",
      "g. Offer personalized solutions tailored to the specific needs of clients.\n",
      "h. Establish a strong online presence through a user-friendly website and active social media accounts.\n",
      "i. Participate in tech conferences and events to network and showcase the company's expertise.\n",
      "j. Offer training and workshops for clients to fully utilize the technology.\n",
      "\n",
      "2. \"MindMeld AI\":\n",
      "a. Build partnerships with companies in various industries to showcase the versatility of the technology.\n",
      "b. Develop a strong online presence through a well-designed website and active social media accounts.\n",
      "c. Utilize targeted marketing to reach potential clients in industries such as healthcare, finance, and retail.\n",
      "d. Offer personalized solutions and customization options to cater to the specific needs\n"
     ]
    }
   ],
   "source": [
    "print(simpleChain.run(\"artificial intelligence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template_name=PromptTemplate(\n",
    "# input_variables=[\"startup_name\"],\n",
    "#     template=\"I want to start a startup for {startup-name} , suggest me a good name for this\"   \n",
    "# )\n",
    "\n",
    "# name_chain=LLMChain(llm=client,prompt=prompt_template_name)\n",
    "\n",
    "# prompt_template_items=PromptTemplate(\n",
    "# input_variables=[\"name\"],\n",
    "#     template=\"suggest some strategies for {name}\"    \n",
    "# )\n",
    "\n",
    "# strategies_chain=LLMChain(llm=client,prompt=prompt_template_items)\n",
    "\n",
    "# from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# chain=SimpleSequentialChain(chains=[name_chain,strategies_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(chain.run(\"artifical intelligence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=[\"cuisine\"],\n",
    "    template=\"i want to open a resturant for {cuisine}, suggest me a fancy name for it \"\n",
    ")\n",
    "\n",
    "name_chain=LLMChain(llm=client,prompt=prompt_template_name,output_key=\"resturant_name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_item=PromptTemplate(\n",
    "    input_variables=[\"resturant_name\"],\n",
    "    template=\"suggest some menu item for {resturant_name}\"\n",
    ")\n",
    "\n",
    "food_item_chain=LLMChain(llm=client,prompt=prompt_template_item,output_key=\"menu_item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=SequentialChain(chains=[name_chain, food_item_chain],\n",
    "    input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"resturant_name\",\"menu_item\"]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'indian',\n",
       " 'resturant_name': '\\n\"Maharaja\\'s Palace\" \\n',\n",
       " 'menu_item': '1. Tandoori Chicken - marinated chicken grilled in a clay oven \\n2. Butter Chicken - tender chicken cooked in a rich tomato and butter gravy \\n3. Lamb Rogan Josh - slow-cooked lamb in a spicy tomato-based sauce \\n4. Vegetable Biryani - fragrant basmati rice cooked with mixed vegetables and spices \\n5. Palak Paneer - cottage cheese cubes cooked in creamy spinach gravy \\n6. Chicken Tikka Masala - chunks of chicken cooked in a creamy tomato-based sauce \\n7. Dal Makhani - slow-cooked black lentils in a rich and creamy sauce \\n8. Naan - traditional Indian flatbread, available in various flavors such as garlic, cheese, or onion \\n9. Samosas - crispy pastry filled with spiced potatoes and peas \\n10. Mango Lassi - a refreshing yogurt-based drink blended with mangoes.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"cuisine\":\"indian\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to read a document using lanchain model - i.e using document loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader(r\"D:\\BIMRA.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages=loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day-5- memory concept and hugging face api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=OpenAI(openai_api_key=OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "template1=PromptTemplate(\n",
    "    input_variables=['product'],\n",
    "    template=\"what is a good name for a company that makes {product}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rainbow Cups Co.\n"
     ]
    }
   ],
   "source": [
    "chain=LLMChain(llm=client,prompt=template1)\n",
    "print(chain.run(\"colorfull cups\").strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.memory    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain.memory) #conclusion- we are not going to sustain any memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converstion buffer memory\n",
    "\n",
    "**we can attach memoery to remeber preveius conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory=ConversationBufferMemory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "template1=PromptTemplate(\n",
    "    input_variables=['product'],\n",
    "    template=\"what is a good name for a company that makes {product}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=client,memory=memory,prompt=template1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Vinoteca\\n2. Grapevine Vintners\\n3. Vino Veritas Co.\\n4. Cellar Door Wines\\n5. Harvest Moon Winery\\n6. Noble Vines Ltd.\\n7. Vintage Reserve Co.\\n8. Redwood Ridge Winery\\n9. Chateau de Luxe\\n10. Terroir Wines Inc.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"wines\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' bags\\n\\n\"Capture Gear Co.\" \\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. SkyLink Technologies\\n2. AeroVision Drones\\n3. FlyHigh Innovations\\n4. Winged Ventures\\n5. DroneWorks Co.\\n6. Airborne Dynamics\\n7. SkyScape Solutions\\n8. FlightTech Industries\\n9. Aerial Innovations Inc.\\n10. DroneForce Enterprises'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"drone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='wines'), AIMessage(content='\\n\\n1. Vinoteca\\n2. Grapevine Vintners\\n3. Vino Veritas Co.\\n4. Cellar Door Wines\\n5. Harvest Moon Winery\\n6. Noble Vines Ltd.\\n7. Vintage Reserve Co.\\n8. Redwood Ridge Winery\\n9. Chateau de Luxe\\n10. Terroir Wines Inc.'), HumanMessage(content='camera'), AIMessage(content=' bags\\n\\n\"Capture Gear Co.\" \\n'), HumanMessage(content='drone'), AIMessage(content='\\n\\n1. SkyLink Technologies\\n2. AeroVision Drones\\n3. FlyHigh Innovations\\n4. Winged Ventures\\n5. DroneWorks Co.\\n6. Airborne Dynamics\\n7. SkyScape Solutions\\n8. FlightTech Industries\\n9. Aerial Innovations Inc.\\n10. DroneForce Enterprises')]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: wines\n",
      "AI: \n",
      "\n",
      "1. Vinoteca\n",
      "2. Grapevine Vintners\n",
      "3. Vino Veritas Co.\n",
      "4. Cellar Door Wines\n",
      "5. Harvest Moon Winery\n",
      "6. Noble Vines Ltd.\n",
      "7. Vintage Reserve Co.\n",
      "8. Redwood Ridge Winery\n",
      "9. Chateau de Luxe\n",
      "10. Terroir Wines Inc.\n",
      "Human: camera\n",
      "AI:  bags\n",
      "\n",
      "\"Capture Gear Co.\" \n",
      "\n",
      "Human: drone\n",
      "AI: \n",
      "\n",
      "1. SkyLink Technologies\n",
      "2. AeroVision Drones\n",
      "3. FlyHigh Innovations\n",
      "4. Winged Ventures\n",
      "5. DroneWorks Co.\n",
      "6. Airborne Dynamics\n",
      "7. SkyScape Solutions\n",
      "8. FlightTech Industries\n",
      "9. Aerial Innovations Inc.\n",
      "10. DroneForce Enterprises\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='wines'), AIMessage(content='\\n\\n1. Vinoteca\\n2. Grapevine Vintners\\n3. Vino Veritas Co.\\n4. Cellar Door Wines\\n5. Harvest Moon Winery\\n6. Noble Vines Ltd.\\n7. Vintage Reserve Co.\\n8. Redwood Ridge Winery\\n9. Chateau de Luxe\\n10. Terroir Wines Inc.'), HumanMessage(content='camera'), AIMessage(content=' bags\\n\\n\"Capture Gear Co.\" \\n'), HumanMessage(content='drone'), AIMessage(content='\\n\\n1. SkyLink Technologies\\n2. AeroVision Drones\\n3. FlyHigh Innovations\\n4. Winged Ventures\\n5. DroneWorks Co.\\n6. Airborne Dynamics\\n7. SkyScape Solutions\\n8. FlightTech Industries\\n9. Aerial Innovations Inc.\\n10. DroneForce Enterprises')]\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer_as_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converstation chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converstaion buffere memory goes growing endlessely\n",
    "just remember last 5 converstation chain\n",
    "just remember last 10-20 conversation chain\n",
    "\n",
    "why do we use  coverstatinon chian when we have buffer memory, lets understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo=ConversationChain(llm=OpenAI(openai_api_key=OPENAI_KEY, temperature=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['history', 'input'], template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The first cricket world cup was held in 1975 and was won by the West Indies team. The final match was played between West Indies and Australia, with West Indies emerging as the victors with a score of 291/8. The tournament was hosted by England and was a 60-over per side competition. Interestingly, the man of the match in the final was West Indies' captain Clive Lloyd, who scored a century and led his team to victory.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who won the first cricket world cup.?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Of course! The answer to 10+2 is 12. Would you like me to provide any additional calculations or information?'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"can you tell me how much is 10+2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The color orange is a combination of red and yellow, and falls between the two on the color spectrum. It is often associated with energy, warmth, and happiness. Did you know that orange is also the name of a fruit, which gets its name from the color of its skin?'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what is the color of orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The captain of the winning team in the first cricket world cup was Clive Lloyd, who was also named the man of the match. He is a former West Indian cricketer who played for the West Indies national team from 1966 to 1985. Lloyd is considered one of the greatest cricketers of all time and is credited for leading the West Indies team to many victories, including the first cricket world cup.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who is the captain of winning team.?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from above we observe that it is able to sustain the conversation using converstation chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#conversation buuffer memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by using conversation buffere memeory we can control the height of the window through which we want to sustain the converstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory=ConversationBufferMemory(k=1) # the meaning of k parameter says that it will sustain memeory for just one prompt and then it will not be able to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo2=ConversationChain(llm=OpenAI(openai_api_key=OPENAI_KEY, temperature=0.7),memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first cricket world cup was held in 1975 and was won by the West Indies. The West Indies defeated Australia by 17 runs in the final match. Did you know that the first cricket world cup had a total of eight teams participating and was hosted by England?'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo2.run(\"who won the first cricket world cup.?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Of course, 10+2 is equal to 12. Is there anything else you would like to know about the first cricket world cup?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo2.run(\"can you tell me how much is 10+2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The color of an orange fruit is typically orange, as the name suggests. However, did you know that the color orange is named after the fruit and not the other way around? The color was first referred to as \"geoluhread\" in Old English, which translates to \"yellow-red.\" It wasn\\'t until the 16th century that the word \"orange\" was used to describe the color.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo2.run(\"what is the color of orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The captain of the winning team for the first cricket world cup in 1975 was Clive Lloyd of the West Indies. He was also the captain for the West Indies team that won the second cricket world cup in 1979. Did you know that he was inducted into the ICC Cricket Hall of Fame in 2009?'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo2.run(\"who is the captain of winning team.?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
